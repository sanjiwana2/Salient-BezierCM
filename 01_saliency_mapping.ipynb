{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3357002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "import glob, os\n",
    "\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1330b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Paths\n",
    "Forest_Drive = \"./Data/Forest\"\n",
    "NonForest_Drive = \"./Data/Non_Forest\"\n",
    "\n",
    "forest_images = glob.glob(os.path.join(Forest_Drive, \"**/*.tif\"))\n",
    "nonforest_images = glob.glob(os.path.join(NonForest_Drive, \"**/*.tif\"))\n",
    "\n",
    "print(f\"Total forest images found: {len(forest_images)}\")\n",
    "print(f\"Total non-forest images found: {len(nonforest_images)}\")\n",
    "\n",
    "# Sample 2000 images from each, if possible\n",
    "forest_sample = random.sample(forest_images, min(2000, len(forest_images)))\n",
    "nonforest_sample = random.sample(nonforest_images, min(2000, len(nonforest_images)))\n",
    "\n",
    "print(f\"Sampled {len(forest_sample)} forest images\")\n",
    "print(f\"Sampled {len(nonforest_sample)} non-forest images\")\n",
    "\n",
    "# Labels: Forest=1, NonForest=0\n",
    "image_path = forest_sample + nonforest_sample\n",
    "labels = [1]*len(forest_images) + [0]*len(nonforest_images)\n",
    "print(len(image_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1b7d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import torch\n",
    "\n",
    "class CustomGeoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Read 4-band image with rasterio\n",
    "        with rasterio.open(img_path) as src:\n",
    "            image = src.read()  # shape: (bands, height, width)\n",
    "\n",
    "        # Normalize to 0-1\n",
    "        image = image.astype('float32')\n",
    "        for b in range(image.shape[0]):\n",
    "            band = image[b]\n",
    "            band = (band - band.min()) / (band.max() - band.min() + 1e-8)\n",
    "            image[b] = band\n",
    "\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "\n",
    "        # Optional: apply transforms (resize, etc.)\n",
    "        # Optional resize\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            import torch.nn.functional as F\n",
    "            image = F.interpolate(image.unsqueeze(0), size=(380,380), mode='bilinear', align_corners=False).squeeze(0)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e67f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomGeoDataset(image_path, labels)\n",
    "\n",
    "# Train/test split\n",
    "split_size = 0.8\n",
    "train_size = int(split_size * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_data, test_data = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae65882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "model = models.efficientnet_b4(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "# original first conv\n",
    "orig_conv = model.features[0][0]   # Conv2d(3,48,...)\n",
    "\n",
    "# create new conv with 4 input channels\n",
    "new_conv = nn.Conv2d(\n",
    "    in_channels=4,\n",
    "    out_channels=orig_conv.out_channels,\n",
    "    kernel_size=orig_conv.kernel_size,\n",
    "    stride=orig_conv.stride,\n",
    "    padding=orig_conv.padding,\n",
    "    bias=orig_conv.bias is not None\n",
    ")\n",
    "\n",
    "# copy weights for first 3 channels\n",
    "with torch.no_grad():\n",
    "    new_conv.weight[:, :3, :, :] = orig_conv.weight\n",
    "    new_conv.weight[:, 3:, :, :] = torch.randn_like(new_conv.weight[:, 3:, :, :]) * 0.01\n",
    "\n",
    "# replace\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)  # 1 output\n",
    "model.features[0][0] = new_conv\n",
    "\n",
    "model = model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba0405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14e0d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "num_epochs = 50  # adjust as needed\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    all_labels_train = []\n",
    "    all_preds_train = []\n",
    "\n",
    "    # -------------------\n",
    "    # Training loop\n",
    "    # -------------------\n",
    "    for i, (x, y) in enumerate(trainloader):\n",
    "        x = x.to(DEVICE, dtype=torch.float32)\n",
    "        y = y.to(DEVICE, dtype=torch.float32).unsqueeze(1)  # shape [batch,1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(x)\n",
    "        loss = criterion(yhat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        preds = (torch.sigmoid(yhat) > 0.5).int()\n",
    "        all_preds_train.extend(preds.detach().cpu().numpy().flatten())\n",
    "        all_labels_train.extend(y.detach().cpu().numpy().flatten())\n",
    "\n",
    "    # Training metrics\n",
    "    train_acc = accuracy_score(all_labels_train, all_preds_train)\n",
    "    train_prec = precision_score(all_labels_train, all_preds_train, zero_division=0)\n",
    "    train_rec = recall_score(all_labels_train, all_preds_train, zero_division=0)\n",
    "    train_f1 = f1_score(all_labels_train, all_preds_train, zero_division=0)\n",
    "\n",
    "    # -------------------\n",
    "    # Evaluation on test data\n",
    "    # -------------------\n",
    "    model.eval()\n",
    "    all_labels_test = []\n",
    "    all_preds_test = []\n",
    "    with torch.no_grad():\n",
    "        for x_test, y_test in testloader:\n",
    "            x_test = x_test.to(DEVICE, dtype=torch.float32)\n",
    "            y_test = y_test.to(DEVICE, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "            yhat_test = model(x_test)\n",
    "            preds_test = (torch.sigmoid(yhat_test) > 0.5).int()\n",
    "\n",
    "            all_preds_test.extend(preds_test.cpu().numpy().flatten())\n",
    "            all_labels_test.extend(y_test.cpu().numpy().flatten())\n",
    "\n",
    "    test_acc = accuracy_score(all_labels_test, all_preds_test)\n",
    "    test_prec = precision_score(all_labels_test, all_preds_test, zero_division=0)\n",
    "    test_rec = recall_score(all_labels_test, all_preds_test, zero_division=0)\n",
    "    test_f1 = f1_score(all_labels_test, all_preds_test, zero_division=0)\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train Loss: {running_loss/len(trainloader):.4f} | \"\n",
    "          f\"Train Acc: {train_acc:.4f} | Train Prec: {train_prec:.4f} | \"\n",
    "          f\"Train Rec: {train_rec:.4f} | Train F1: {train_f1:.4f} | \"\n",
    "          f\"Test Acc: {test_acc:.4f} | Test Prec: {test_prec:.4f} | \"\n",
    "          f\"Test Rec: {test_rec:.4f} | Test F1: {test_f1:.4f}\")\n",
    "\n",
    "    # -------------------\n",
    "    # Save metrics to history\n",
    "    # -------------------\n",
    "    history.append({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": running_loss / len(trainloader),\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_prec\": train_prec,\n",
    "        \"train_rec\": train_rec,\n",
    "        \"train_f1\": train_f1,\n",
    "        \"test_acc\": test_acc,\n",
    "        \"test_prec\": test_prec,\n",
    "        \"test_rec\": test_rec,\n",
    "        \"test_f1\": test_f1\n",
    "    })\n",
    "\n",
    "# -------------------\n",
    "# Save to CSV\n",
    "# -------------------\n",
    "df_history = pd.DataFrame(history)\n",
    "df_history.to_csv(\"train_test_metrics.csv\", index=False)\n",
    "print(\"Saved metrics to train_test_metrics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96573b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- After training ---\n",
    "model_path = \"./efficientb4_2k_forest_nonforest.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect features\n",
    "print(model.features[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107a3270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def contrast_stretch(img, low_pct=2, high_pct=98):\n",
    "    \"\"\"\n",
    "    Apply percentile-based contrast stretch on a 3-channel image.\n",
    "    img: np.array of shape (H,W,C), float or int\n",
    "    \"\"\"\n",
    "    out = np.zeros_like(img, dtype=np.float32)\n",
    "    for c in range(img.shape[2]):\n",
    "        low, high = np.percentile(img[:,:,c], (low_pct, high_pct))\n",
    "        out[:,:,c] = np.clip((img[:,:,c] - low) / (high - low + 1e-8), 0, 1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1fbe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GradCAM on a test image ---\n",
    "target_layers = [model.features[-1][0]]  # last Conv2d\n",
    "\n",
    "# pick one test sample\n",
    "test_img, test_label = test_data[0]\n",
    "input_tensor = test_img.unsqueeze(0).to(DEVICE)\n",
    "\n",
    "# --- Prepare 321 composite ---\n",
    "rgb_img_321 = test_img[[2,1,0]].numpy()  # bands 3,2,1\n",
    "rgb_img_321 = np.transpose(rgb_img_321, (1,2,0))  # (H,W,C)\n",
    "\n",
    "# --- Contrast stretch ---\n",
    "rgb_img_321_stretched = contrast_stretch(rgb_img_321, 2, 98)\n",
    "\n",
    "with GradCAM(model=model, target_layers=target_layers) as cam:\n",
    "    grayscale_cam = cam(input_tensor=input_tensor)\n",
    "    grayscale_cam_norm = (grayscale_cam[0] - grayscale_cam[0].min()) / (grayscale_cam[0].max() - grayscale_cam[0].min() + 1e-8) \n",
    "\n",
    "cam_mask = grayscale_cam[0] if grayscale_cam.ndim==3 else grayscale_cam\n",
    "cam_mask_uint8 = np.uint8(255 * cam_mask)\n",
    "\n",
    "cam_image = show_cam_on_image(rgb_img_321_stretched, cam_mask_uint8, use_rgb=True)\n",
    "\n",
    "# --- Create heatmap with colormap ---\n",
    "heatmap = cm.jet(grayscale_cam_norm)[:, :, :3]  # convert to RGB\n",
    "\n",
    "# Overlay CAM on RGB image\n",
    "cam_overlay = 0.5 * rgb_img_321_stretched + 0.5 * heatmap\n",
    "cam_overlay = np.clip(cam_overlay, 0, 1)\n",
    "\n",
    "# --- Plot side by side ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,6))\n",
    "\n",
    "# Original image\n",
    "axes[0].imshow(rgb_img_321_stretched)\n",
    "axes[0].set_title(\"Original Image (321 Composite)\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# Grad-CAM overlay\n",
    "im = axes[1].imshow(cam_overlay)\n",
    "axes[1].set_title(f\"Grad-CAM Overlay\\nTrue Label: {int(test_label.item())}\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "# Add colorbar for activation intensity\n",
    "cbar = fig.colorbar(cm.ScalarMappable(cmap='jet'), ax=axes[1], fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Activation Intensity', rotation=270, labelpad=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3af78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def extract_regions_from_cam(cam_mask, threshold=0.2, min_area=1000):\n",
    "    \"\"\"\n",
    "    cam_mask: 2D array normalized 0..1 (grayscale_cam_norm or similar)\n",
    "    returns: labeled_mask, list of region dicts {label, area, bbox, centroid, coords_mask}\n",
    "    \"\"\"\n",
    "    bw = (cam_mask >= threshold).astype(np.uint8)\n",
    "    # remove tiny islands\n",
    "    bw = ndimage.binary_opening(bw, structure=np.ones((3,3))).astype(np.uint8)\n",
    "    labeled, n = ndimage.label(bw)\n",
    "    regions = []\n",
    "    for lab in range(1, n+1):\n",
    "        coords = np.argwhere(labeled == lab)  # rows (y), cols (x)\n",
    "        area = coords.shape[0]\n",
    "        if area < min_area:\n",
    "            continue\n",
    "        ys = coords[:,0]\n",
    "        xs = coords[:,1]\n",
    "        cy = ys.mean()\n",
    "        cx = xs.mean()\n",
    "        y0, x0, y1, x1 = ys.min(), xs.min(), ys.max(), xs.max()\n",
    "        regions.append({\n",
    "            \"label\": lab,\n",
    "            \"area\": int(area),\n",
    "            \"bbox\": (int(x0), int(y0), int(x1), int(y1)),\n",
    "            \"centroid\": (float(cx), float(cy)),\n",
    "            \"coords\": coords\n",
    "        })\n",
    "    return labeled, regions\n",
    "\n",
    "def bezier_like_polygon_points(center, area_pixels, img_shape, n_points=8, \n",
    "                               min_scale=0.6, max_scale=1.3, jitter_angle=0.5):\n",
    "    \"\"\"\n",
    "    Create polygon points around center. radius scales with sqrt(area).\n",
    "    center: (cx, cy) in pixel coordinates (x,y)\n",
    "    area_pixels: area (number of pix) of the high-activation region\n",
    "    img_shape: (H, W)\n",
    "    returns: list of (x,y) float points\n",
    "    \"\"\"\n",
    "    H, W = img_shape\n",
    "    cx, cy = center\n",
    "    # base radius from area: radius that would have same area if circular\n",
    "    base_radius = np.sqrt(area_pixels / np.pi)\n",
    "    # scale to be larger a bit\n",
    "    mean_radius = max(4.0, base_radius * 1.5)  # at least a few px\n",
    "    angles = np.linspace(0, 2*np.pi, n_points, endpoint=False)\n",
    "    angles += np.random.uniform(-jitter_angle, jitter_angle, size=n_points)\n",
    "    radii = np.random.uniform(min_scale, max_scale, size=n_points) * mean_radius\n",
    "    xs = cx + radii * np.cos(angles)\n",
    "    ys = cy + radii * np.sin(angles)\n",
    "    pts = np.stack([xs, ys], axis=1)\n",
    "    # clip to image bounds\n",
    "    pts[:,0] = np.clip(pts[:,0], 0, W-1)\n",
    "    pts[:,1] = np.clip(pts[:,1], 0, H-1)\n",
    "    return pts.tolist()\n",
    "\n",
    "def smooth_polygon(points, smoothing_radius=3):\n",
    "    \"\"\"\n",
    "    Given polygon points as list[(x,y)], upsample and apply Gaussian smoothing to coordinates\n",
    "    to create a smoother curve. Returns list[(x,y)] int suitable for rasterization.\n",
    "    \"\"\"\n",
    "    pts = np.array(points, dtype=np.float32)\n",
    "    # close loop\n",
    "    pts_closed = np.vstack([pts, pts[0:1,:]])\n",
    "    # param t along polygon\n",
    "    t = np.linspace(0, 1, len(pts_closed))\n",
    "    # upsample\n",
    "    t_up = np.linspace(0, 1, max(64, len(pts_closed)*8))\n",
    "    xs = np.interp(t_up, t, pts_closed[:,0])\n",
    "    ys = np.interp(t_up, t, pts_closed[:,1])\n",
    "    # gaussian smooth\n",
    "    k = max(1, int(smoothing_radius))\n",
    "    xs = cv2.GaussianBlur(xs.reshape(1,-1).astype(np.float32), (1, k|1), sigmaX=smoothing_radius).flatten()\n",
    "    ys = cv2.GaussianBlur(ys.reshape(1,-1).astype(np.float32), (1, k|1), sigmaX=smoothing_radius).flatten()\n",
    "    poly = np.stack([xs, ys], axis=1)\n",
    "    # convert to ints for rasterization\n",
    "    poly_int = [(int(round(x)), int(round(y))) for x,y in poly]\n",
    "    return poly_int\n",
    "\n",
    "def polygon_to_mask(poly_pts, img_shape, soften_sigma=3):\n",
    "    \"\"\"\n",
    "    Rasterize polygon points to a float mask [0,1], optionally soften with gaussian blur\n",
    "    poly_pts: list of (x,y) ints\n",
    "    \"\"\"\n",
    "    H, W = img_shape\n",
    "    mask = np.zeros((H, W), dtype=np.uint8)\n",
    "    if len(poly_pts) >= 3:\n",
    "        cv2.fillPoly(mask, [np.array(poly_pts, dtype=np.int32)], color=1)\n",
    "    mask = mask.astype(np.float32)\n",
    "    if soften_sigma > 0:\n",
    "        k = max(3, int(soften_sigma*4)|1)\n",
    "        mask = cv2.GaussianBlur(mask, (k,k), soften_sigma)\n",
    "        # normalize to 0..1\n",
    "        if mask.max() > 0:\n",
    "            mask = mask / mask.max()\n",
    "    return mask\n",
    "\n",
    "# ---------------------------\n",
    "# Example usage (after computing grayscale_cam and rgb_img_321_stretched)\n",
    "# grayscale_cam_norm should be 2D in 0..1 (H,W)\n",
    "# ---------------------------\n",
    "\n",
    "# assume you have:\n",
    "# grayscale_cam_norm  (H,W) float in [0,1]\n",
    "# rgb_img_321_stretched (H,W,3) float in [0,1]\n",
    "\n",
    "threshold = 0.8\n",
    "min_area = 10  # min pixels for region to be considered\n",
    "labeled, regions = extract_regions_from_cam(grayscale_cam_norm, threshold=threshold, min_area=min_area)\n",
    "\n",
    "masks = []\n",
    "polygons = []\n",
    "\n",
    "H, W = grayscale_cam_norm.shape\n",
    "\n",
    "for r in regions:\n",
    "    centroid = r[\"centroid\"]  # (cx, cy) in pixels (note: x,y)\n",
    "    area = r[\"area\"]\n",
    "    # Determine number of control/sample points depending on area\n",
    "    n_points = 6 + int(min(12, max(0, np.log1p(area)/0.5)))  # between 6 and ~12\n",
    "    base_pts = bezier_like_polygon_points(center=centroid, area_pixels=area, img_shape=(H,W), n_points=n_points)\n",
    "    poly_smooth = smooth_polygon(base_pts, smoothing_radius=max(2, int(np.sqrt(area)/6)))\n",
    "    mask = polygon_to_mask(poly_smooth, (H,W), soften_sigma=max(1.0, np.sqrt(area)/8.0))\n",
    "    masks.append(mask)\n",
    "    polygons.append(poly_smooth)\n",
    "\n",
    "# If you want a combined mask with multiple regions (logical OR)\n",
    "if len(masks) > 0:\n",
    "    combined_mask = np.clip(np.sum(np.stack(masks, axis=0), axis=0), 0, 1)\n",
    "else:\n",
    "    combined_mask = np.zeros_like(grayscale_cam_norm)\n",
    "\n",
    "# Visualization example: show mask outlines on image\n",
    "vis = (rgb_img_321_stretched.copy()*255).astype(np.uint8)\n",
    "for poly in polygons:\n",
    "    cv2.polylines(vis, [np.array(poly, dtype=np.int32)], isClosed=True, color=(255,0,0), thickness=2)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(rgb_img_321_stretched)\n",
    "plt.title(\"321 composite (stretched)\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(vis)\n",
    "plt.title(\"polygons from CAM regions\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# masks: list of float masks [H,W] in 0..1 (soft edges)\n",
    "# polygons: list of list[(x,y)] integer polygon coordinates\n",
    "# combined_mask: aggregate mask (0..1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17894c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import binom\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bernstein = lambda n, k, t: binom(n, k) * t**k * (1.-t)**(n-k)\n",
    "\n",
    "def bezier(points, num=200):\n",
    "    N = len(points)\n",
    "    t = np.linspace(0, 1, num=num)\n",
    "    curve = np.zeros((num, 2))\n",
    "    for i in range(N):\n",
    "        curve += np.outer(bernstein(N - 1, i, t), points[i])\n",
    "    return curve\n",
    "\n",
    "class Segment():\n",
    "    def __init__(self, p1, p2, angle1, angle2, **kw):\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        self.angle1 = angle1\n",
    "        self.angle2 = angle2\n",
    "        self.numpoints = kw.get(\"numpoints\", 100)\n",
    "        r = kw.get(\"r\", 0.3)\n",
    "        d = np.sqrt(np.sum((self.p2 - self.p1)**2))\n",
    "        self.r = r * d\n",
    "        self.p = np.zeros((4, 2))\n",
    "        self.p[0, :] = self.p1[:]\n",
    "        self.p[3, :] = self.p2[:]\n",
    "        self.calc_intermediate_points(self.r)\n",
    "\n",
    "    def calc_intermediate_points(self, r):\n",
    "        self.p[1, :] = self.p1 + np.array([self.r * np.cos(self.angle1),\n",
    "                                           self.r * np.sin(self.angle1)])\n",
    "        self.p[2, :] = self.p2 + np.array([self.r * np.cos(self.angle2 + np.pi),\n",
    "                                           self.r * np.sin(self.angle2 + np.pi)])\n",
    "        self.curve = bezier(self.p, self.numpoints)\n",
    "\n",
    "def get_curve(points, **kw):\n",
    "    segments = []\n",
    "    for i in range(len(points) - 1):\n",
    "        seg = Segment(points[i, :2], points[i + 1, :2], points[i, 2], points[i + 1, 2], **kw)\n",
    "        segments.append(seg)\n",
    "    curve = np.concatenate([s.curve for s in segments])\n",
    "    return segments, curve\n",
    "\n",
    "def ccw_sort(p):\n",
    "    d = p - np.mean(p, axis=0)\n",
    "    s = np.arctan2(d[:, 0], d[:, 1])\n",
    "    return p[np.argsort(s), :]\n",
    "\n",
    "def get_bezier_curve(a, rad=0.2, edgy=0):\n",
    "    \"\"\" given an array of points *a*, create a curve through\n",
    "    those points. \n",
    "    *rad* is a number between 0 and 1 to steer the distance of\n",
    "          control points.\n",
    "    *edgy* is a parameter which controls how \"edgy\" the curve is,\n",
    "           edgy=0 is smoothest.\"\"\"\n",
    "    p = np.arctan(edgy) / np.pi + .5\n",
    "    a = ccw_sort(a)\n",
    "    a = np.append(a, np.atleast_2d(a[0, :]), axis=0)\n",
    "    d = np.diff(a, axis=0)\n",
    "    ang = np.arctan2(d[:, 1], d[:, 0])\n",
    "    f = lambda ang: (ang >= 0) * ang + (ang < 0) * (ang + 2 * np.pi)\n",
    "    ang = f(ang)\n",
    "    ang1 = ang\n",
    "    ang2 = np.roll(ang, 1)\n",
    "    ang = p * ang1 + (1 - p) * ang2 + (np.abs(ang2 - ang1) > np.pi) * np.pi\n",
    "    ang = np.append(ang, [ang[0]])\n",
    "    a = np.append(a, np.atleast_2d(ang).T, axis=1)\n",
    "    s, c = get_curve(a, r=rad, method=\"var\")\n",
    "    x, y = c.T\n",
    "    return x, y, a\n",
    "\n",
    "def get_random_points(n=5, scale=0.8, mindst=None, rec=0):\n",
    "    \"\"\" create n random points in the unit square, which are *mindst*\n",
    "    apart, then scale them.\"\"\"\n",
    "    mindst = mindst or .7 / n\n",
    "    a = np.random.rand(n, 2)\n",
    "    d = np.sqrt(np.sum(np.diff(ccw_sort(a), axis=0), axis=1)**2)\n",
    "    if np.all(d >= mindst) or rec >= 200:\n",
    "        return a * scale\n",
    "    else:\n",
    "        return get_random_points(n=n, scale=scale, mindst=mindst, rec=rec + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef81a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def cam_region_to_bezier_mask(cam_mask, threshold=0.8, rad=0.3, edgy=0.2, blur_radius=5):\n",
    "    \"\"\"\n",
    "    Convert high-activation CAM regions into soft Bezier masks.\n",
    "    cam_mask: 2D np.array normalized [0,1]\n",
    "    threshold: activation threshold\n",
    "    blur_radius: Gaussian blur radius for soft boundaries\n",
    "    Convert high-activation CAM regions into Bezier masks (clipped to image size, with optional blur).\n",
    "    Returns: list of (polygon_points, polygon_mask)\n",
    "    \"\"\"\n",
    "    H, W = cam_mask.shape\n",
    "    bw = (cam_mask >= threshold).astype(np.uint8)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    results = []\n",
    "\n",
    "    for cnt in contours:\n",
    "        if len(cnt) < 5:\n",
    "            continue\n",
    "        pts = cnt.squeeze()\n",
    "        if pts.ndim != 2 or pts.shape[0] < 5:\n",
    "            continue\n",
    "\n",
    "        # Convex hull for smoother boundary\n",
    "        hull = cv2.convexHull(pts).squeeze().astype(np.float32)\n",
    "\n",
    "        # --- Get Bezier curve ---\n",
    "        x, y, _ = get_bezier_curve(hull, rad=rad, edgy=edgy)\n",
    "\n",
    "        # --- Clip coordinates to valid image bounds ---\n",
    "        x = np.clip(x, 0, W - 1)\n",
    "        y = np.clip(y, 0, H - 1)\n",
    "\n",
    "        # --- Round to int for polygon rasterization ---\n",
    "        poly_points = [(int(xi), int(yi)) for xi, yi in zip(x, y)]\n",
    "\n",
    "        # --- Create polygon mask ---\n",
    "        img_mask = Image.new(\"L\", (W, H), 0)\n",
    "        ImageDraw.Draw(img_mask).polygon(poly_points, outline=1, fill=1)\n",
    "        poly_mask = np.array(img_mask, dtype=np.uint8)\n",
    "\n",
    "        # --- Apply Gaussian blur (optional feathering) ---\n",
    "        if blur_radius > 0:\n",
    "            poly_mask = cv2.GaussianBlur(poly_mask.astype(np.float32), \n",
    "                                         (0, 0), blur_radius)\n",
    "            poly_mask = np.clip(poly_mask, 0, 1)  # normalize back to [0,1]\n",
    "\n",
    "        results.append((poly_points, poly_mask))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c084c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Example usage ----------------\n",
    "results = cam_region_to_bezier_mask(grayscale_cam_norm, threshold=0.4, rad=0.4, edgy=0.3, blur_radius=8)\n",
    "\n",
    "# Combine masks (clipped automatically)\n",
    "H, W = grayscale_cam_norm.shape\n",
    "mask_total = np.zeros((H, W), dtype=np.uint8)\n",
    "for _, poly_mask in results:\n",
    "    mask_total = np.maximum(mask_total, poly_mask)\n",
    "\n",
    "# --- Visualization ---\n",
    "plt.figure(figsize=(18,6))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(rgb_img_321_stretched)\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(rgb_img_321_stretched)\n",
    "im = plt.imshow(grayscale_cam_norm, cmap='jet', alpha=0.5)\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "plt.title(\"Grad-CAM Overlay\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(rgb_img_321_stretched)\n",
    "plt.imshow(mask_total, cmap='Reds', alpha=0.4)\n",
    "for poly_points, _ in results:\n",
    "    plt.plot([p[0] for p in poly_points], [p[1] for p in poly_points], 'r-', linewidth=2)\n",
    "plt.title(\"Bezier Mask Overlay (Soft Edges)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1437321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def cam_region_to_bezier_mask(cam_mask, threshold=0.8, rad=0.3, edgy=0.2):\n",
    "    \"\"\"\n",
    "    Convert high-activation CAM regions into Bezier masks (clipped to image size).\n",
    "    Returns: list of (polygon_points, polygon_mask)\n",
    "    \"\"\"\n",
    "    H, W = cam_mask.shape\n",
    "    bw = (cam_mask >= threshold).astype(np.uint8)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    results = []\n",
    "\n",
    "    for cnt in contours:\n",
    "        if len(cnt) < 5:\n",
    "            continue\n",
    "        pts = cnt.squeeze()\n",
    "        if pts.ndim != 2 or pts.shape[0] < 5:\n",
    "            continue\n",
    "\n",
    "        # Convex hull for smoothness\n",
    "        hull = cv2.convexHull(pts).squeeze().astype(np.float32)\n",
    "\n",
    "        # Get Bezier curve\n",
    "        x, y, _ = get_bezier_curve(hull, rad=rad, edgy=edgy)\n",
    "\n",
    "        # --- Clip to valid image bounds ---\n",
    "        x = np.clip(x, 0, W - 1)\n",
    "        y = np.clip(y, 0, H - 1)\n",
    "\n",
    "        # Build polygon points (integer coordinates)\n",
    "        poly_points = [(int(xi), int(yi)) for xi, yi in zip(x, y)]\n",
    "\n",
    "        # --- Rasterize polygon mask ---\n",
    "        img_mask = Image.new('L', (W, H), 0)\n",
    "        ImageDraw.Draw(img_mask).polygon(poly_points, outline=1, fill=1)\n",
    "        poly_mask = np.array(img_mask, dtype=np.uint8)\n",
    "\n",
    "        results.append((poly_points, poly_mask))\n",
    "\n",
    "        '''\n",
    "        # Get Bezier curve\n",
    "        x, y, _ = get_bezier_curve(hull, rad=rad, edgy=edgy)\n",
    "        poly_points = list(zip(x, y))\n",
    "\n",
    "        # --- Rasterize polygon mask ---\n",
    "        img_mask = Image.new('L', (W, H), 0)\n",
    "        ImageDraw.Draw(img_mask).polygon(poly_points, outline=1, fill=1)\n",
    "        poly_mask = np.array(img_mask, dtype=np.uint8)\n",
    "\n",
    "        results.append((poly_points, poly_mask))\n",
    "        '''\n",
    "\n",
    "    return results\n",
    "\n",
    "# ---------------- Example usage ----------------\n",
    "results = cam_region_to_bezier_mask(grayscale_cam_norm, threshold=0.35, rad=0.8, edgy=0.5)\n",
    "\n",
    "# Combine masks (clipped automatically)\n",
    "H, W = grayscale_cam_norm.shape\n",
    "mask_total = np.zeros((H, W), dtype=np.uint8)\n",
    "for _, poly_mask in results:\n",
    "    mask_total = np.maximum(mask_total, poly_mask)\n",
    "\n",
    "# --- Visualization ---\n",
    "plt.figure(figsize=(18,6))\n",
    "\n",
    "# 1. Show CAM directly\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(rgb_img_321_stretched)\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "# 2. Overlay CAM on original image\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(rgb_img_321_stretched)\n",
    "im = plt.imshow(grayscale_cam_norm, cmap='jet', alpha=0.5)  # heatmap overlay\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04) \n",
    "plt.title(\"Grad-CAM Overlay\")\n",
    "\n",
    "# 3. Overlay Bezier masks on original image\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(rgb_img_321_stretched)\n",
    "plt.imshow(mask_total, cmap='Reds', alpha=0.4)  # overlay masks\n",
    "for poly_points, _ in results:\n",
    "    plt.plot([p[0] for p in poly_points], [p[1] for p in poly_points], 'r-', linewidth=2)\n",
    "plt.title(\"Bezier Mask Overlay\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868367a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# ----------------------\n",
    "# Albumentations Transform\n",
    "# ----------------------\n",
    "geo_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.1, scale_limit=0.2, rotate_limit=30,\n",
    "        interpolation=1, border_mode=0, p=0.7\n",
    "    )\n",
    "])\n",
    "\n",
    "def tensor_to_numpy(image_tensor):\n",
    "    \"\"\"Convert tensor (C,H,W) -> numpy (H,W,C) for Albumentations.\"\"\"\n",
    "    return image_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "def numpy_to_tensor(image_np):\n",
    "    \"\"\"Convert numpy (H,W,C) -> tensor (C,H,W).\"\"\"\n",
    "    return torch.from_numpy(image_np).permute(2, 0, 1).float()\n",
    "\n",
    "\n",
    "def apply_albumentations(image_tensor, transform=geo_transform):\n",
    "    \"\"\"Apply Albumentations transform to a 4-band tensor image.\"\"\"\n",
    "    image_np = tensor_to_numpy(image_tensor)\n",
    "    augmented = transform(image=image_np)\n",
    "    return numpy_to_tensor(augmented[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d0e8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Model.salient_bezier_cutmix as sbc\n",
    "print(dir(sbc))\n",
    "\n",
    "from  Model.salient_bezier_cutmix import salient_cutmix_pipeline\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "n = 50\n",
    "\n",
    "Target_Drive = \"./Data_3/Forest\" # data that will multiplied by mask\n",
    "Source_Drive = \"./Data_3/NonForest\" # data that will multiplied by mask and added to the target drive\n",
    "out_img_drive = \"./Data_3/Augmented_Image\"\n",
    "out_label_drive = \"./Data_3/Augmented_Label\"\n",
    "\n",
    "os.makedirs(out_img_drive, exist_ok=True)\n",
    "os.makedirs(out_label_drive, exist_ok=True)\n",
    "\n",
    "salient_cutmix_pipeline(\n",
    "    model=model,\n",
    "    target_drive=Target_Drive,\n",
    "    source_drive=Source_Drive,\n",
    "    out_img_drive=out_img_drive,\n",
    "    out_label_drive=out_label_drive,\n",
    "    n=n,\n",
    "    device=DEVICE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ce3274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# NumPy\n",
    "import numpy as np\n",
    "\n",
    "# OpenCV\n",
    "import cv2\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# PIL\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "\n",
    "# TorchVision\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# Grad-CAM\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "# SciPy\n",
    "from scipy import ndimage\n",
    "from scipy.special import binom\n",
    "\n",
    "# RasterIO\n",
    "import rasterio\n",
    "from rasterio.transform import Affine\n",
    "\n",
    "# Albumentations\n",
    "import albumentations as A\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class CustomGeoDataset2(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        #label = self.labels[idx]\n",
    "\n",
    "        # Read 4-band image with rasterio\n",
    "        with rasterio.open(img_path) as src:\n",
    "            image = src.read()  # shape: (bands, height, width)\n",
    "\n",
    "        # Normalize to 0-1\n",
    "        image = image.astype('float32')\n",
    "        for b in range(image.shape[0]):\n",
    "            band = image[b]\n",
    "            band = (band - band.min()) / (band.max() - band.min() + 1e-8)\n",
    "            image[b] = band\n",
    "\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "\n",
    "        # Optional: apply transforms (resize, etc.)\n",
    "        # Optional resize\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = F.interpolate(image.unsqueeze(0), size=(380,380), mode='bilinear', align_corners=False).squeeze(0)\n",
    "\n",
    "        return image\n",
    "\n",
    "def load_random_paths(base_dir, n):\n",
    "    all_files = [os.path.join(base_dir, f) for f in os.listdir(base_dir) if f.endswith(\".tif\")]\n",
    "    return random.sample(all_files, min(n, len(all_files)))\n",
    "\n",
    "def load_and_preprocess(img_path, size=(256, 256)):\n",
    "    \"\"\"Load GeoTIFF with rasterio and normalize\"\"\"\n",
    "    with rasterio.open(img_path) as src:\n",
    "        img = src.read().astype(\"float32\")  # (C, H, W)\n",
    "\n",
    "    # Normalize band-wise\n",
    "    for b in range(img.shape[0]):\n",
    "        band = img[b]\n",
    "        img[b] = (band - band.min()) / (band.max() - band.min() + 1e-8)\n",
    "\n",
    "    # Resize to (C, 256, 256)\n",
    "    img_tensor = torch.tensor(img).unsqueeze(0)  # (1, C, H, W)\n",
    "    img_resized = F.interpolate(img_tensor, size=size, mode=\"bilinear\", align_corners=False)\n",
    "    return img_resized.squeeze(0).numpy()  # (C, H, W)\n",
    "\n",
    "def contrast_stretch(img, low_pct=2, high_pct=98):\n",
    "    \"\"\"\n",
    "    Apply percentile-based contrast stretch on a 3-channel image.\n",
    "    img: np.array of shape (H,W,C), float or int\n",
    "    \"\"\"\n",
    "    out = np.zeros_like(img, dtype=np.float32)\n",
    "    for c in range(img.shape[2]):\n",
    "        low, high = np.percentile(img[:,:,c], (low_pct, high_pct))\n",
    "        out[:,:,c] = np.clip((img[:,:,c] - low) / (high - low + 1e-8), 0, 1)\n",
    "    return out\n",
    "\n",
    "def extract_regions_from_cam(cam_mask, threshold=0.2, min_area=1000):\n",
    "    \"\"\"\n",
    "    cam_mask: 2D array normalized 0..1 (grayscale_cam_norm or similar)\n",
    "    returns: labeled_mask, list of region dicts {label, area, bbox, centroid, coords_mask}\n",
    "    \"\"\"\n",
    "    bw = (cam_mask >= threshold).astype(np.uint8)\n",
    "    # remove tiny islands\n",
    "    bw = ndimage.binary_opening(bw, structure=np.ones((3,3))).astype(np.uint8)\n",
    "    labeled, n = ndimage.label(bw)\n",
    "    regions = []\n",
    "    for lab in range(1, n+1):\n",
    "        coords = np.argwhere(labeled == lab)  # rows (y), cols (x)\n",
    "        area = coords.shape[0]\n",
    "        if area < min_area:\n",
    "            continue\n",
    "        ys = coords[:,0]\n",
    "        xs = coords[:,1]\n",
    "        cy = ys.mean()\n",
    "        cx = xs.mean()\n",
    "        y0, x0, y1, x1 = ys.min(), xs.min(), ys.max(), xs.max()\n",
    "        regions.append({\n",
    "            \"label\": lab,\n",
    "            \"area\": int(area),\n",
    "            \"bbox\": (int(x0), int(y0), int(x1), int(y1)),\n",
    "            \"centroid\": (float(cx), float(cy)),\n",
    "            \"coords\": coords\n",
    "        })\n",
    "    return labeled, regions\n",
    "\n",
    "def bezier_like_polygon_points(center, area_pixels, img_shape, n_points=8, \n",
    "                               min_scale=0.6, max_scale=1.3, jitter_angle=0.5):\n",
    "    \"\"\"\n",
    "    Create polygon points around center. radius scales with sqrt(area).\n",
    "    center: (cx, cy) in pixel coordinates (x,y)\n",
    "    area_pixels: area (number of pix) of the high-activation region\n",
    "    img_shape: (H, W)\n",
    "    returns: list of (x,y) float points\n",
    "    \"\"\"\n",
    "    H, W = img_shape\n",
    "    cx, cy = center\n",
    "    # base radius from area: radius that would have same area if circular\n",
    "    base_radius = np.sqrt(area_pixels / np.pi)\n",
    "    # scale to be larger a bit\n",
    "    mean_radius = max(4.0, base_radius * 1.5)  # at least a few px\n",
    "    angles = np.linspace(0, 2*np.pi, n_points, endpoint=False)\n",
    "    angles += np.random.uniform(-jitter_angle, jitter_angle, size=n_points)\n",
    "    radii = np.random.uniform(min_scale, max_scale, size=n_points) * mean_radius\n",
    "    xs = cx + radii * np.cos(angles)\n",
    "    ys = cy + radii * np.sin(angles)\n",
    "    pts = np.stack([xs, ys], axis=1)\n",
    "    # clip to image bounds\n",
    "    pts[:,0] = np.clip(pts[:,0], 0, W-1)\n",
    "    pts[:,1] = np.clip(pts[:,1], 0, H-1)\n",
    "    return pts.tolist()\n",
    "\n",
    "def smooth_polygon(points, smoothing_radius=3):\n",
    "    \"\"\"\n",
    "    Given polygon points as list[(x,y)], upsample and apply Gaussian smoothing to coordinates\n",
    "    to create a smoother curve. Returns list[(x,y)] int suitable for rasterization.\n",
    "    \"\"\"\n",
    "    pts = np.array(points, dtype=np.float32)\n",
    "    # close loop\n",
    "    pts_closed = np.vstack([pts, pts[0:1,:]])\n",
    "    # param t along polygon\n",
    "    t = np.linspace(0, 1, len(pts_closed))\n",
    "    # upsample\n",
    "    t_up = np.linspace(0, 1, max(64, len(pts_closed)*8))\n",
    "    xs = np.interp(t_up, t, pts_closed[:,0])\n",
    "    ys = np.interp(t_up, t, pts_closed[:,1])\n",
    "    # gaussian smooth\n",
    "    k = max(1, int(smoothing_radius))\n",
    "    xs = cv2.GaussianBlur(xs.reshape(1,-1).astype(np.float32), (1, k|1), sigmaX=smoothing_radius).flatten()\n",
    "    ys = cv2.GaussianBlur(ys.reshape(1,-1).astype(np.float32), (1, k|1), sigmaX=smoothing_radius).flatten()\n",
    "    poly = np.stack([xs, ys], axis=1)\n",
    "    # convert to ints for rasterization\n",
    "    poly_int = [(int(round(x)), int(round(y))) for x,y in poly]\n",
    "    return poly_int\n",
    "\n",
    "def polygon_to_mask(poly_pts, img_shape, soften_sigma=3):\n",
    "    \"\"\"\n",
    "    Rasterize polygon points to a float mask [0,1], optionally soften with gaussian blur\n",
    "    poly_pts: list of (x,y) ints\n",
    "    \"\"\"\n",
    "    H, W = img_shape\n",
    "    mask = np.zeros((H, W), dtype=np.uint8)\n",
    "    if len(poly_pts) >= 3:\n",
    "        cv2.fillPoly(mask, [np.array(poly_pts, dtype=np.int32)], color=1)\n",
    "    mask = mask.astype(np.float32)\n",
    "    if soften_sigma > 0:\n",
    "        k = max(3, int(soften_sigma*4)|1)\n",
    "        mask = cv2.GaussianBlur(mask, (k,k), soften_sigma)\n",
    "        # normalize to 0..1\n",
    "        if mask.max() > 0:\n",
    "            mask = mask / mask.max()\n",
    "    return mask\n",
    "\n",
    "bernstein = lambda n, k, t: binom(n, k) * t**k * (1.-t)**(n-k)\n",
    "\n",
    "def bezier(points, num=200):\n",
    "    N = len(points)\n",
    "    t = np.linspace(0, 1, num=num)\n",
    "    curve = np.zeros((num, 2))\n",
    "    for i in range(N):\n",
    "        curve += np.outer(bernstein(N - 1, i, t), points[i])\n",
    "    return curve\n",
    "\n",
    "class Segment():\n",
    "    def __init__(self, p1, p2, angle1, angle2, **kw):\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        self.angle1 = angle1\n",
    "        self.angle2 = angle2\n",
    "        self.numpoints = kw.get(\"numpoints\", 100)\n",
    "        r = kw.get(\"r\", 0.3)\n",
    "        d = np.sqrt(np.sum((self.p2 - self.p1)**2))\n",
    "        self.r = r * d\n",
    "        self.p = np.zeros((4, 2))\n",
    "        self.p[0, :] = self.p1[:]\n",
    "        self.p[3, :] = self.p2[:]\n",
    "        self.calc_intermediate_points(self.r)\n",
    "\n",
    "    def calc_intermediate_points(self, r):\n",
    "        self.p[1, :] = self.p1 + np.array([self.r * np.cos(self.angle1),\n",
    "                                           self.r * np.sin(self.angle1)])\n",
    "        self.p[2, :] = self.p2 + np.array([self.r * np.cos(self.angle2 + np.pi),\n",
    "                                           self.r * np.sin(self.angle2 + np.pi)])\n",
    "        self.curve = bezier(self.p, self.numpoints)\n",
    "\n",
    "def get_curve(points, **kw):\n",
    "    segments = []\n",
    "    for i in range(len(points) - 1):\n",
    "        seg = Segment(points[i, :2], points[i + 1, :2], points[i, 2], points[i + 1, 2], **kw)\n",
    "        segments.append(seg)\n",
    "    curve = np.concatenate([s.curve for s in segments])\n",
    "    return segments, curve\n",
    "\n",
    "def ccw_sort(p):\n",
    "    d = p - np.mean(p, axis=0)\n",
    "    s = np.arctan2(d[:, 0], d[:, 1])\n",
    "    return p[np.argsort(s), :]\n",
    "\n",
    "def get_bezier_curve(a, rad=0.2, edgy=0):\n",
    "    \"\"\" given an array of points *a*, create a curve through\n",
    "    those points. \n",
    "    *rad* is a number between 0 and 1 to steer the distance of\n",
    "          control points.\n",
    "    *edgy* is a parameter which controls how \"edgy\" the curve is,\n",
    "           edgy=0 is smoothest.\"\"\"\n",
    "    p = np.arctan(edgy) / np.pi + .5\n",
    "    a = ccw_sort(a)\n",
    "    a = np.append(a, np.atleast_2d(a[0, :]), axis=0)\n",
    "    d = np.diff(a, axis=0)\n",
    "    ang = np.arctan2(d[:, 1], d[:, 0])\n",
    "    f = lambda ang: (ang >= 0) * ang + (ang < 0) * (ang + 2 * np.pi)\n",
    "    ang = f(ang)\n",
    "    ang1 = ang\n",
    "    ang2 = np.roll(ang, 1)\n",
    "    ang = p * ang1 + (1 - p) * ang2 + (np.abs(ang2 - ang1) > np.pi) * np.pi\n",
    "    ang = np.append(ang, [ang[0]])\n",
    "    a = np.append(a, np.atleast_2d(ang).T, axis=1)\n",
    "    s, c = get_curve(a, r=rad, method=\"var\")\n",
    "    x, y = c.T\n",
    "    return x, y, a\n",
    "\n",
    "def get_random_points(n=5, scale=0.8, mindst=None, rec=0):\n",
    "    \"\"\" create n random points in the unit square, which are *mindst*\n",
    "    apart, then scale them.\"\"\"\n",
    "    mindst = mindst or .7 / n\n",
    "    a = np.random.rand(n, 2)\n",
    "    d = np.sqrt(np.sum(np.diff(ccw_sort(a), axis=0), axis=1)**2)\n",
    "    if np.all(d >= mindst) or rec >= 200:\n",
    "        return a * scale\n",
    "    else:\n",
    "        return get_random_points(n=n, scale=scale, mindst=mindst, rec=rec + 1)\n",
    "\n",
    "def cam_region_to_bezier_mask(cam_mask, threshold=0.8, rad=0.3, edgy=0.2, blur_radius=5):\n",
    "    \"\"\"\n",
    "    Convert high-activation CAM regions into soft Bezier masks.\n",
    "    cam_mask: 2D np.array normalized [0,1]\n",
    "    threshold: activation threshold\n",
    "    blur_radius: Gaussian blur radius for soft boundaries\n",
    "    Convert high-activation CAM regions into Bezier masks (clipped to image size, with optional blur).\n",
    "    Returns: list of (polygon_points, polygon_mask)\n",
    "    \"\"\"\n",
    "    H, W = cam_mask.shape\n",
    "    bw = (cam_mask >= threshold).astype(np.uint8)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    results = []\n",
    "\n",
    "    for cnt in contours:\n",
    "        if len(cnt) < 5:\n",
    "            continue\n",
    "        pts = cnt.squeeze()\n",
    "        if pts.ndim != 2 or pts.shape[0] < 5:\n",
    "            continue\n",
    "\n",
    "        # Convex hull for smoother boundary\n",
    "        hull = cv2.convexHull(pts).squeeze().astype(np.float32)\n",
    "\n",
    "        # --- Get Bezier curve ---\n",
    "        x, y, _ = get_bezier_curve(hull, rad=rad, edgy=edgy)\n",
    "\n",
    "        # --- Clip coordinates to valid image bounds ---\n",
    "        x = np.clip(x, 0, W - 1)\n",
    "        y = np.clip(y, 0, H - 1)\n",
    "\n",
    "        # --- Round to int for polygon rasterization ---\n",
    "        poly_points = [(int(xi), int(yi)) for xi, yi in zip(x, y)]\n",
    "\n",
    "        # --- Create polygon mask ---\n",
    "        img_mask = Image.new(\"L\", (W, H), 0)\n",
    "        ImageDraw.Draw(img_mask).polygon(poly_points, outline=1, fill=1)\n",
    "        poly_mask = np.array(img_mask, dtype=np.uint8)\n",
    "\n",
    "        # --- Apply Gaussian blur (optional feathering) ---\n",
    "        if blur_radius > 0:\n",
    "            poly_mask = cv2.GaussianBlur(poly_mask.astype(np.float32), \n",
    "                                         (0, 0), blur_radius)\n",
    "            poly_mask = np.clip(poly_mask, 0, 1)  # normalize back to [0,1]\n",
    "\n",
    "        results.append((poly_points, poly_mask))\n",
    "\n",
    "    return results\n",
    "\n",
    "geom_transform = A.Compose(\n",
    "    [\n",
    "        A.HorizontalFlip(p=0.9),\n",
    "        A.VerticalFlip(p=0.9),\n",
    "        A.RandomRotate90(p=0.9),\n",
    "    ],\n",
    "    additional_targets={\n",
    "        \"raw\": \"image\",\n",
    "        \"target\": \"image\"\n",
    "    }\n",
    ")\n",
    "\n",
    "def apply_cam_and_mask(model, img_array, device=\"cuda\"):\n",
    "    \"\"\"Run model -> CAM -> Bezier mask\"\"\"\n",
    "    model.eval()\n",
    "    target_layers = [model.features[-1][0]]  # last Conv2d\n",
    "    img_tensor = img_array.unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    with GradCAM(model=model, target_layers=target_layers) as cam:\n",
    "        gcam = cam(input_tensor=img_tensor)\n",
    "        # Normalize CAM\n",
    "        gcam = (gcam - gcam.min()) / (gcam.max() - gcam.min() + 1e-8)\n",
    "        gcam = gcam.squeeze()\n",
    "    \n",
    "    # Generate mask\n",
    "    masks = cam_region_to_bezier_mask(gcam, threshold=0.3, rad=0.9, edgy=0.5, blur_radius=2)\n",
    "\n",
    "    H, W = gcam.shape\n",
    "    mask_total = np.zeros((H, W), dtype=np.uint8)\n",
    "    for _, poly_mask in masks:\n",
    "        mask_total = np.maximum(mask_total, poly_mask)\n",
    "\n",
    "    # Resize to 256×256\n",
    "    mask_resized = cv2.resize(mask_total, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return mask_resized\n",
    "\n",
    "def salient_cutmix_pipeline(model, target_drive, source_drive, out_img_drive, out_label_drive, n=500, device=\"cuda\"):\n",
    "    target_paths = load_random_paths(target_drive, n)\n",
    "    source_paths = load_random_paths(source_drive, n)\n",
    "\n",
    "    for i, (target_path, source_path) in enumerate(zip(target_paths, source_paths)):\n",
    "        # --- Load normalized (for CAM) ---\n",
    "        s_img = CustomGeoDataset2([source_path], transform=None)[0]  # normalized (C,H,W)\n",
    "        s_img = s_img.numpy().transpose(1, 2, 0)  # HWC in [0,1]\n",
    "\n",
    "        # --- Load unnormalized (for blending) ---\n",
    "        with rasterio.open(source_path) as src:\n",
    "            s2_img = src.read().transpose(1, 2, 0).astype(np.float32)  # original values\n",
    "            s2_img = cv2.resize(s2_img, (380, 380), interpolation=cv2.INTER_LINEAR)\n",
    "            #src_profile = src.profile\n",
    "\n",
    "        # --- Apply SAME augmentation to both normalized + unnormalized ---\n",
    "        aug_out = geom_transform(image=s_img, raw=s2_img)\n",
    "        s_aimg = aug_out[\"image\"]   # normalized → for CAM\n",
    "        s2_aimg = aug_out[\"raw\"]    # unnormalized → for blending\n",
    "\n",
    "        # --- Saliency mask from normalized ---\n",
    "        s_aimg = np.transpose(s_aimg, (2, 0, 1))\n",
    "        s_tensor = torch.tensor(s_aimg, dtype=torch.float32).to(device)\n",
    "        mask = apply_cam_and_mask(model, s_tensor, device=device)  # (H,W)\n",
    "        mask_binary = (mask > 0.25).astype(np.uint8)\n",
    "\n",
    "        # --- Load and augment target ---\n",
    "        with rasterio.open(target_path) as tgt:\n",
    "            profile = tgt.profile\n",
    "            t_img = tgt.read().transpose(1, 2, 0).astype(np.float32)\n",
    "\n",
    "        t_aimg = geom_transform(image=t_img)[\"image\"]\n",
    "\n",
    "        # --- Blend in original value space ---\n",
    "        mask_expanded = np.expand_dims(mask, axis=-1).astype(np.float32)\n",
    "        s2_aimg = cv2.resize(s2_img, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "        t_aimg = cv2.resize(t_aimg, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "        mixed_img = mask_expanded * s2_aimg + (1 - mask_expanded) * t_aimg\n",
    "\n",
    "        # --- Prepare profiles ---\n",
    "        img_profile = profile.copy()\n",
    "        img_profile.update({\n",
    "            \"count\": mixed_img.shape[2],\n",
    "            \"dtype\": \"float32\"\n",
    "        })\n",
    "\n",
    "        label_profile = profile.copy()\n",
    "        label_profile.update({\n",
    "            \"count\": 1,\n",
    "            \"dtype\": \"uint8\"\n",
    "        })\n",
    "\n",
    "        # --- Save results ---\n",
    "        out_img_path = os.path.join(out_img_drive, f\"aug_{i:04d}.tif\")\n",
    "        with rasterio.open(out_img_path, \"w\", **img_profile) as dst:\n",
    "            for b in range(mixed_img.shape[2]):\n",
    "                dst.write(mixed_img[:, :, b], b + 1)\n",
    "\n",
    "        out_label_path = os.path.join(out_label_drive, f\"aug_{i:04d}.tif\")\n",
    "        with rasterio.open(out_label_path, \"w\", **label_profile) as dst:\n",
    "            dst.write(mask_binary, 1)\n",
    "\n",
    "        print(f\"[{i+1}/{n}] Saved -> {out_img_path}, {out_label_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967e4b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_paths = load_random_paths(Forest_Drive, n)\n",
    "source_paths = load_random_paths(NonForest_Drive, n)\n",
    "\n",
    "geom_transform = A.Compose(\n",
    "    [\n",
    "        A.HorizontalFlip(p=0.9),\n",
    "        A.VerticalFlip(p=0.9),\n",
    "        A.RandomRotate90(p=0.9),\n",
    "    ],\n",
    "    additional_targets={\n",
    "        \"raw\": \"image\",\n",
    "        \"target\": \"image\"\n",
    "    }\n",
    ")\n",
    "\n",
    "for i, (target_path, source_path) in enumerate(zip(target_paths, source_paths)):\n",
    "    # --- Load normalized (for CAM) ---\n",
    "    s_img = CustomGeoDataset2([source_path], transform=None)[0]  # normalized (C,H,W)\n",
    "    s_img = s_img.numpy().transpose(1, 2, 0)  # HWC in [0,1]\n",
    "\n",
    "    # --- Load unnormalized (for blending) ---\n",
    "    with rasterio.open(source_path) as src:\n",
    "        s2_img = src.read().transpose(1, 2, 0).astype(np.float32)  # original values\n",
    "        s2_img = cv2.resize(s2_img, (380, 380), interpolation=cv2.INTER_LINEAR)\n",
    "        #src_profile = src.profile\n",
    "\n",
    "    # --- Apply SAME augmentation to both normalized + unnormalized ---\n",
    "    aug_out = geom_transform(image=s_img, raw=s2_img)\n",
    "    s_aimg = aug_out[\"image\"]   # normalized → for CAM\n",
    "    s2_aimg = aug_out[\"raw\"]    # unnormalized → for blending\n",
    "\n",
    "    # --- Saliency mask from normalized ---\n",
    "    s_aimg = np.transpose(s_aimg, (2, 0, 1))\n",
    "    s_tensor = torch.tensor(s_aimg, dtype=torch.float32).to(DEVICE)\n",
    "    mask = apply_cam_and_mask(model, s_tensor, device=DEVICE)  # (H,W)\n",
    "    mask_binary = (mask > 0.25).astype(np.uint8)\n",
    "\n",
    "    # --- Load and augment target ---\n",
    "    with rasterio.open(target_path) as tgt:\n",
    "        profile = tgt.profile\n",
    "        t_img = tgt.read().transpose(1, 2, 0).astype(np.float32)\n",
    "\n",
    "    t_aimg = geom_transform(image=t_img)[\"image\"]\n",
    "\n",
    "    # --- Blend in original value space ---\n",
    "    mask_expanded = np.expand_dims(mask, axis=-1).astype(np.float32)\n",
    "    s2_aimg = cv2.resize(s2_img, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "    t_aimg = cv2.resize(t_aimg, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "    mixed_img = mask_expanded * s2_aimg + (1 - mask_expanded) * t_aimg\n",
    "\n",
    "    # --- Prepare profiles ---\n",
    "    img_profile = profile.copy()\n",
    "    img_profile.update({\n",
    "        \"count\": mixed_img.shape[2],\n",
    "        \"dtype\": \"float32\"\n",
    "    })\n",
    "\n",
    "    label_profile = profile.copy()\n",
    "    label_profile.update({\n",
    "        \"count\": 1,\n",
    "        \"dtype\": \"float32\"\n",
    "    })\n",
    "    \n",
    "    # --- Save results ---\n",
    "    out_img_path = os.path.join(out_img_drive, f\"aug_image_{i:04d}.tif\")\n",
    "    with rasterio.open(out_img_path, \"w\", **img_profile) as dst:\n",
    "        for b in range(mixed_img.shape[2]):\n",
    "            dst.write(mixed_img[:, :, b], b + 1)\n",
    "\n",
    "    out_label_path = os.path.join(out_label_drive, f\"aug_label_{i:04d}.tif\")\n",
    "    with rasterio.open(out_label_path, \"w\", **label_profile) as dst:\n",
    "        dst.write(mask_binary, 1)\n",
    "\n",
    "    print(f\"[{i+1}/{n}] Saved -> {out_img_path}, {out_label_path}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
